{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d99cc44-802b-400c-bdc5-34959e88bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6295a384-20fd-4cfd-ae3f-be332c4b1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3e2edf-b56d-45ed-9203-1663b0083b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip evals_run_1.zip\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913d6203-9d45-4887-a694-3ad56641b489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526406b-a80a-4352-a4aa-798d4eebfb85",
   "metadata": {},
   "source": [
    "# Is the same dataset used for eval across all checkpoints? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348776e-8ba1-4a60-842b-98e9cde8c079",
   "metadata": {},
   "source": [
    "## Are the prompts the same across all eval steps? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa8e978-08ba-48d1-9455-7edcb5943811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "steps = [100, 200, 300, 400, 500, 597]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "633d1396-de86-4850-9edc-f1318b70a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_per_step = []\n",
    "\n",
    "for step in steps:\n",
    "    data = load_from_disk(f\"evals/step_{step}/alphabet-sort\")\n",
    "    prompts = data[\"prompt\"]\n",
    "    assert len(prompts) == 2048, \"There should be 2048 prompts, each\"\n",
    "    prompts_per_step.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da0422b7-86fd-4611-80c3-84fdc045ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same prompt across all steps? True\n"
     ]
    }
   ],
   "source": [
    "# Check if all prompts are the same\n",
    "all_equal = all(prompts_per_step[0] == p for p in prompts_per_step)\n",
    "print(\"Same prompt across all steps?\" , all_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ade9e-f14d-47c7-8b57-67432b597835",
   "metadata": {},
   "source": [
    "## Answer: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d660c-ec8c-4d9c-824d-b1993b3e447f",
   "metadata": {},
   "source": [
    "## Are infos the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc219bfe-1dfb-4cf8-9d34-c95ead9e7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_per_step = []\n",
    "\n",
    "for step in steps:\n",
    "    data = load_from_disk(f\"evals/step_{step}/alphabet-sort\")\n",
    "    infos = data[\"info\"]\n",
    "    assert len(infos) == 2048, \"There should be 2048 infos, each\"\n",
    "    infos_per_step.append(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22cc4a2f-8c1f-4b18-8b35-864faa281b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same info col across all steps? True\n"
     ]
    }
   ],
   "source": [
    "# Check if all infos are the same\n",
    "all_equal = all(infos_per_step[0] == p for p in infos_per_step)\n",
    "print(\"Same info col across all steps?\" , all_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb544ea-8779-473a-99da-75d506b06171",
   "metadata": {},
   "source": [
    "## Answer: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14363325-13d9-45ff-8aaf-ff5aef8e09c3",
   "metadata": {},
   "source": [
    "## Are prompts + infos the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d073d10-c46a-4c57-a777-f93e4a7e4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_per_step = []\n",
    "\n",
    "for step in steps:\n",
    "    data = load_from_disk(f\"evals/step_{step}/alphabet-sort\")\n",
    "    joint_data = [row[\"prompt\"][0][\"content\"][0][\"text\"] + row[\"info\"] for row in data]\n",
    "    assert len(joint_data) == 2048, \"there should be 2048 rows\"\n",
    "    joint_per_step.append(joint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ecbfb32-c4b8-409b-909b-96354872b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same joint row across all steps? True\n"
     ]
    }
   ],
   "source": [
    "# Check if all joint infos are the same\n",
    "all_equal = all(joint_per_step[0] == p for p in joint_per_step)\n",
    "print(\"Same joint row across all steps?\" , all_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f57d0-eb19-41fc-adf4-57a8ef4b9f6b",
   "metadata": {},
   "source": [
    "## Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
