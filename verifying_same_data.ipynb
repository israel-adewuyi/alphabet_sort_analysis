{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d99cc44-802b-400c-bdc5-34959e88bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6295a384-20fd-4cfd-ae3f-be332c4b1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets pandas huggingface_hub\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3e2edf-b56d-45ed-9203-1663b0083b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip evals.zip\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526406b-a80a-4352-a4aa-798d4eebfb85",
   "metadata": {},
   "source": [
    "# Is the same dataset used for eval across all checkpoints? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348776e-8ba1-4a60-842b-98e9cde8c079",
   "metadata": {},
   "source": [
    "## Are the prompts the same across all eval steps? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa8e978-08ba-48d1-9455-7edcb5943811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "steps = [100, 200, 300, 400, 500, 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633d1396-de86-4850-9edc-f1318b70a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_per_step = []\n",
    "\n",
    "for step in steps:\n",
    "    data = load_from_disk(f\"evals/step_{step}/alphabet-sort\")\n",
    "    prompts = data[\"prompt\"]\n",
    "    assert len(prompts) == 2048, \"There should be 2048 prompts, each\"\n",
    "    prompts_per_step.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0422b7-86fd-4611-80c3-84fdc045ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same prompt across all steps? True\n"
     ]
    }
   ],
   "source": [
    "# Check if all prompts are the same\n",
    "all_equal = all(prompts_per_step[0] == p for p in prompts_per_step)\n",
    "print(\"Same prompt across all steps?\" , all_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ade9e-f14d-47c7-8b57-67432b597835",
   "metadata": {},
   "source": [
    "## Answer: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d660c-ec8c-4d9c-824d-b1993b3e447f",
   "metadata": {},
   "source": [
    "## Are infos the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc219bfe-1dfb-4cf8-9d34-c95ead9e7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_per_step = []\n",
    "\n",
    "for step in steps:\n",
    "    data = load_from_disk(f\"evals/step_{step}/alphabet-sort\")\n",
    "    infos = data[\"info\"]\n",
    "    assert len(infos) == 2048, \"There should be 2048 infos, each\"\n",
    "    infos_per_step.append(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22cc4a2f-8c1f-4b18-8b35-864faa281b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same info col across all steps? True\n"
     ]
    }
   ],
   "source": [
    "# Check if all infos are the same\n",
    "all_equal = all(infos_per_step[0] == p for p in infos_per_step)\n",
    "print(\"Same info col across all steps?\" , all_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb544ea-8779-473a-99da-75d506b06171",
   "metadata": {},
   "source": [
    "## Answer: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14363325-13d9-45ff-8aaf-ff5aef8e09c3",
   "metadata": {},
   "source": [
    "## Are prompts + infos the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d073d10-c46a-4c57-a777-f93e4a7e4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_per_step = []\n",
    "\n",
    "for step in steps:\n",
    "    data = load_from_disk(f\"evals/step_{step}/alphabet-sort\")\n",
    "    joint_data = [row[\"prompt\"][0][\"content\"][0][\"text\"] + row[\"info\"] for row in data]\n",
    "    assert len(joint_data) == 2048, \"there should be 2048 rows\"\n",
    "    joint_per_step.append(joint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ecbfb32-c4b8-409b-909b-96354872b088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same joint row across all steps? True\n"
     ]
    }
   ],
   "source": [
    "# Check if all joint infos are the same\n",
    "all_equal = all(joint_per_step[0] == p for p in joint_per_step)\n",
    "print(\"Same joint row across all steps?\" , all_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f57d0-eb19-41fc-adf4-57a8ef4b9f6b",
   "metadata": {},
   "source": [
    "### Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e69e06-7cdc-4299-95c8-fc725f89dde2",
   "metadata": {},
   "source": [
    "# Save eval data to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71226586-abc2-417b-95c4-42d013f1206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = load_from_disk(\"evals/step_100/alphabet-sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec5b39cd-32d8-4400-8ecf-6dc0f7004ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, full_rollouts = [], []\n",
    "\n",
    "for row in dataset:\n",
    "    prompt = row[\"prompt\"][0][\"content\"][0][\"text\"]\n",
    "    completions = [entry[\"content\"] for entry in row[\"completion\"]]\n",
    "\n",
    "    assert isinstance(prompt, str)\n",
    "    assert isinstance(completions, list)\n",
    "\n",
    "    multiturn_prompts = prompt + \" \".join(completions[1::2])\n",
    "    entire_rollout = prompt + \" \".join(completions)\n",
    "    \n",
    "    prompts.append(multiturn_prompts)\n",
    "    full_rollouts.append(entire_rollout)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'prompt': prompts, 'full_rollout': full_rollouts})\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f0212fb-3dc3-454e-ac31-052b20c6f433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b740caa4084f08b4bd7e76aa24f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af973ea6-8088-4ce9-ad77-daff03f9e706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/israel-adewuyi/eval_data_alphabet_sort/commit/5c1c9e61dce65d40af7e1c4eae74c3c1057536f7', commit_message='Upload data.csv with huggingface_hub', commit_description='', oid='5c1c9e61dce65d40af7e1c4eae74c3c1057536f7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/israel-adewuyi/eval_data_alphabet_sort', endpoint='https://huggingface.co', repo_type='dataset', repo_id='israel-adewuyi/eval_data_alphabet_sort'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "api.create_repo(\"israel-adewuyi/eval_data_alphabet_sort\", repo_type=\"dataset\")\n",
    "\n",
    "from huggingface_hub import upload_file\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=\"data.csv\",\n",
    "    path_in_repo=\"data.csv\",\n",
    "    repo_id=\"israel-adewuyi/eval_data_alphabet_sort\",\n",
    "    repo_type=\"dataset\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
